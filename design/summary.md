# Design

## 秒杀系统
秒杀系统本质上就是一个满足大并发, 高性能和高可用的分布式系统.
秒杀就是同时处理大量的并发读和并发写.

### 架构原则 
如果你是一个架构师, 你首先要勾勒出一个轮廓, 想一想如何构建一个超大流量并发读写, 高性能, 以及高可用的系统, 这其中有哪些要素需要考虑.

* 数据要尽量少

    在网络间传输的数据(请求和回应)能少就少. 
    应用之间的调用能少就少.
    数据越简单, 越小越好.
    数据的压缩, 编码, 序列化等操作都是 CPU 杀手.
    
* 请求数要尽量少

    合并静态文件.
    减少 DNS 解析耗时.
    
* 路径要尽量短

    所谓 "路径", 就是用户发出请求到返回数据这个过程中, 需要经过的中间节点数(服务端调用).
    一种解决方法是将多个相互强依赖的应用合并部署, 把远程过程调用(RPC) 变成 JVM 内部之间的方法调用.
    
* 依赖要尽量少

    所谓依赖, 指的是要完成一次用户请求必须依赖的系统或服务.
    可以给系统进行分级, 保证高优先级的系统不会被低优先级的系统拖跨.    

* 不要有单点

    单点意味着没有备份, 风险不可控. 我们设计分布式系统最重要的原则就是 "消除单点". 
    避免单点的关键是避免将服务的状态和机器绑定, 即把服务无状态化(保护幂等性).
    像存储这类的服务本身很难无状态化. 因为数据要存储在磁盘上, 本身就要和机器绑定, 那么这种场景一般要通过冗余多个备份的方式来解决单点问题.
    
    
**架构是一种平衡的艺术, 最好的架构一旦脱离了它所适应的场景, 一切都将是空谈**.    
要取得极致的性能, 就要在其他方面(如通用性, 易用性, 成本等)有所牺牲.

### 动静分离
动静分离的目标有:
1. 提高单次请求的效率.
2. 减少没必要的请求.

所谓 "动静分离", 其实就是把用户请求的数据划分为 "动态数据" 和 "静态数据".
简单来说, "动态数据" 或 "静态数据" 的主要区别就是看页面中输出的数据是否和 URL, 浏览者, 时间, 地域相关, 以及是否含有 Cookie 等私密数据. 即是否含有和访问者相关的个性化数据.
分离了动静数据, 我们就可以对分离出来的静态数据做缓存, 有了缓存之后, 静态数据的 "访问效率" 自然就提高了.
如何对静态数据做缓存:
1. 你应该把静态数据缓存到离用户最近的地方.

    常见的缓存点有三种: 用户浏览器, CDN 和服务器 Cache. 你应该根据情况, 把它们尽量缓存到离用户最近的地方.

1. 静态化改造就是要直接缓存 HTTP 连接而不是仅仅缓存数据.
2. 让谁来缓存静态数据也很重要. 不同语言写的 Cache 软件处理缓存数据的效率也各不相同.

如何做动静分离:
1. URL 唯一化.
2. 分离浏览者相关的因素. 将个性化数据单独处理.
3. 分离时间因素.
4. 异步化地域因素.
5. 去除缓存数据中的 Cookie.

动态内容的处理通常有两种: ESI(Edge Side Includes) 方案和 CSI(Client Side Include)方案.
1. ESI, SSI: 即在 Web 代理服务器上做动态内容请求, 并将请求插入到静态页面中, 当用户拿到页面时已经是一个完整的页面了. 这种方式对服务端性能有些影响, 但是用户体验较好.
2. CSI: 即单独发起一个异步 JavaScript 请求, 以向服务端获取动态内容. 这种方式服务端性能更佳, 但用户端页面可能会延时, 体验稍差.

动静分离的几种架构方案:
1. 实体机单机部署.
2. 统一 Cache 层.
    Cache 最重要的一个衡量指标就是 "高命中率", 不然 Cache 的存在就失去了意义.
1. 上 CDN.
    在 CDN 上, 我们可以主动更新数据, 而在用户的浏览器里就很难控制了.
    将静态数据缓存到 CDN 的二级 Cache 上比较合适, 因为二级 Cache 数量偏少, 容量也更大. 让用户的请求先回源到 CDN 的二级 Cache 中, 如果没命中再回源到服务器获取数据.
    使用 CDN 的二级 Cache 作为缓存, 可以达到和当前服务端静态化 Cache 类似的命中率, 因为节点数不多, Cache 不是很分散, 访问量也比较集中, 这样也就解决了命中率问题, 同时能够给用户最好的访问体验, 是当前比较理想的一种 CDN 化方案.

### 二八原则 
热点分为 "操作热点" 和 "数据热点".
所谓 "静态热点数据", 就是能够提前预测的热点数据. 而所谓 "动态热点数据", 就是不能被提前预测到的, 系统在运行过程中临时产生的热点.

#### 发现静态热点数据
1. 通过一个运营系统, 把参加活动的商品数据进行打标, 然后通过一个后台系统对这些热点商品进行预处理.
2. 对买家每天访问的商品进行大数据计算, 然后统计出热点商品.

#### 发现动态热点数据
热点发现要做到接近实时, 动态发现才有意义, 才能实时地对下游系统提供保护.
一个具体实现步骤:
1. 构建一个异步的系统, 它可以收集交易链路上各个环节中的中间件产品的热点 Key, 如 Nginx, 缓存, RPC 服务框架等.
2. 建立一个热点上报和可以按需订阅的热点服务的下发规范, 主要目的是通过交易链路上各个系统访问的时间差, 把上游已经发现的热点透传给下游系统, 提前做好保护. 比如大促高峰期, 详情系统是最早知道的.
3. 将上游系统收集的热点数据发送到热点服务台, 然后下游系统(比如交易系统)就会知道哪些商品会被频繁调用, 然后做热点保护.

#### 处理热点数据
常用的思路有: 优化, 限制, 隔离.
优化热点数据最有效的办法就是缓存热点数据.
限制更多的是一种保护机制. 防止因某些热点数据占用太多服务器资源, 而使其他请求始终得不到服务器的处理.
隔离也是为了防止 1% 的请求影响到另外的 99%, 隔离出来后也更方便对这 1% 的请求做针对性的优化.
具体到 "秒杀" 业务, 我们可以在以下几个层次实现隔离:
1. 业务隔离. 把秒杀系统做成一做可以提前预知的活动.
2. 系统隔离. 一般指运行时隔离. 可以通过分组部署或使用单独入口(单独域名)的方法防止影响到其他业务.
3. 数据隔离. 对热点数据使用单独的 Cache 和数据库.


### 流量削峰
秒杀请求在时间上高度集中于某一特定的时间点. 这会导致一个特别高的流量峰值, 它对资源的消耗是瞬时的.
对于秒杀这个场景来说, 最终能够抢到商品的人数是固定的. 并发度越高, 无效请求也越多. 但从业务上来说, 秒杀活动是希望更多的人来参与的.
服务器的处理资源能力是恒定的. 但是由于要保证服务质量, 我们对很多场景的资源需求只能按忙时来预估, 这就会导致资源的浪费. 削峰的存在, 一是可以让服务端处理更加平稳, 二是可以节省服务器的资源成本.

#### 排队
即用消息队列来缓冲瞬时流量. 把同步的直接调用转换成异步的间接推送. 中间通过一个队列在一端承接瞬时的流量洪峰, 在另一端平滑地将消息推送出去.

#### 答题
一是防止部分买家使用秒杀器作弊. 二是延缓请求.
这个功能就是把峰值的请求拉长, 从以前的 1s 内延长到 1s~10s.
秒杀答题的逻辑是:
1. 题库生成. 生成能够防止机器破解的题库.
2. 题库的推送. 用来保证每次用户请求的题目是唯一的, 防止作弊.
3. 题库图片生成. 由于答题时网络比较拥挤, 应该把题库图片提前推送到 CDN 上并进行预热.

可以将题目和答案不可逆加密后推送到客户端, 在用户提交前先在客户端进行验证, 以减少无效请求.

#### 分层过滤
对请求进行层层过滤, 从而去除一些无效的请求. 假如请求分别经过 CDN, 前台读系统, 后台系统和数据库这几层, 那么:
1. 大部分数据和流量在用户浏览器或者 CDN 上获取, 这一层可以拦截大部分数据的读取.
2. 经过前台读系统时数据尽量走 Cache, 过滤一些无效的请求.
3. 在后台系统中对数据做二次检验, 对系统做好保护和限流, 这样数据量和请求就进一步减少.
4. 最后在数据层完成数据的强一致性校验.

这样就像漏斗一样, 尽量把数据量和请求量一层一层地过滤和减少了.
分层过滤的核心思想是: 在不同的层次尽可能地过滤掉无效请求, 让 "漏斗" 最末端的才是有效请求. 
尽量将不影响性能的校验放在前面.





















