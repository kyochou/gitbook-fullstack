# Design

## 秒杀系统
秒杀系统本质上就是一个满足大并发, 高性能和高可用的分布式系统.
秒杀就是同时处理大量的并发读和并发写.

### 架构原则 
如果你是一个架构师, 你首先要勾勒出一个轮廓, 想一想如何构建一个超大流量并发读写, 高性能, 以及高可用的系统, 这其中有哪些要素需要考虑.

* 数据要尽量少

    在网络间传输的数据(请求和回应)能少就少. 
    应用之间的调用能少就少.
    数据越简单, 越小越好.
    数据的压缩, 编码, 序列化等操作都是 CPU 杀手.
    
* 请求数要尽量少

    合并静态文件.
    减少 DNS 解析耗时.
    
* 路径要尽量短

    所谓 "路径", 就是用户发出请求到返回数据这个过程中, 需要经过的中间节点数(服务端调用).
    一种解决方法是将多个相互强依赖的应用合并部署, 把远程过程调用(RPC) 变成 JVM 内部之间的方法调用.
    
* 依赖要尽量少

    所谓依赖, 指的是要完成一次用户请求必须依赖的系统或服务.
    可以给系统进行分级, 保证高优先级的系统不会被低优先级的系统拖跨.    

* 不要有单点

    单点意味着没有备份, 风险不可控. 我们设计分布式系统最重要的原则就是 "消除单点". 
    避免单点的关键是避免将服务的状态和机器绑定, 即把服务无状态化(保护幂等性).
    像存储这类的服务本身很难无状态化. 因为数据要存储在磁盘上, 本身就要和机器绑定, 那么这种场景一般要通过冗余多个备份的方式来解决单点问题.
    
    
**架构是一种平衡的艺术, 最好的架构一旦脱离了它所适应的场景, 一切都将是空谈**.    
要取得极致的性能, 就要在其他方面(如通用性, 易用性, 成本等)有所牺牲.

### 动静分离
动静分离的目标有:
1. 提高单次请求的效率.
2. 减少没必要的请求.

所谓 "动静分离", 其实就是把用户请求的数据划分为 "动态数据" 和 "静态数据".
简单来说, "动态数据" 或 "静态数据" 的主要区别就是看页面中输出的数据是否和 URL, 浏览者, 时间, 地域相关, 以及是否含有 Cookie 等私密数据. 即是否含有和访问者相关的个性化数据.
分离了动静数据, 我们就可以对分离出来的静态数据做缓存, 有了缓存之后, 静态数据的 "访问效率" 自然就提高了.
如何对静态数据做缓存:
1. 你应该把静态数据缓存到离用户最近的地方.

    常见的缓存点有三种: 用户浏览器, CDN 和服务器 Cache. 你应该根据情况, 把它们尽量缓存到离用户最近的地方.

1. 静态化改造就是要直接缓存 HTTP 连接而不是仅仅缓存数据.
2. 让谁来缓存静态数据也很重要. 不同语言写的 Cache 软件处理缓存数据的效率也各不相同.

如何做动静分离:
1. URL 唯一化.
2. 分离浏览者相关的因素. 将个性化数据单独处理.
3. 分离时间因素.
4. 异步化地域因素.
5. 去除缓存数据中的 Cookie.

动态内容的处理通常有两种: ESI(Edge Side Includes) 方案和 CSI(Client Side Include)方案.
1. ESI, SSI: 即在 Web 代理服务器上做动态内容请求, 并将请求插入到静态页面中, 当用户拿到页面时已经是一个完整的页面了. 这种方式对服务端性能有些影响, 但是用户体验较好.
2. CSI: 即单独发起一个异步 JavaScript 请求, 以向服务端获取动态内容. 这种方式服务端性能更佳, 但用户端页面可能会延时, 体验稍差.

动静分离的几种架构方案:
1. 实体机单机部署.
2. 统一 Cache 层.
    Cache 最重要的一个衡量指标就是 "高命中率", 不然 Cache 的存在就失去了意义.
1. 上 CDN.
    在 CDN 上, 我们可以主动更新数据, 而在用户的浏览器里就很难控制了.
    将静态数据缓存到 CDN 的二级 Cache 上比较合适, 因为二级 Cache 数量偏少, 容量也更大. 让用户的请求先回源到 CDN 的二级 Cache 中, 如果没命中再回源到服务器获取数据.
    使用 CDN 的二级 Cache 作为缓存, 可以达到和当前服务端静态化 Cache 类似的命中率, 因为节点数不多, Cache 不是很分散, 访问量也比较集中, 这样也就解决了命中率问题, 同时能够给用户最好的访问体验, 是当前比较理想的一种 CDN 化方案.

### 二八原则 
热点分为 "操作热点" 和 "数据热点".
所谓 "静态热点数据", 就是能够提前预测的热点数据. 而所谓 "动态热点数据", 就是不能被提前预测到的, 系统在运行过程中临时产生的热点.

#### 发现静态热点数据
1. 通过一个运营系统, 把参加活动的商品数据进行打标, 然后通过一个后台系统对这些热点商品进行预处理.
2. 对买家每天访问的商品进行大数据计算, 然后统计出热点商品.

#### 发现动态热点数据
热点发现要做到接近实时, 动态发现才有意义, 才能实时地对下游系统提供保护.
一个具体实现步骤:
1. 构建一个异步的系统, 它可以收集交易链路上各个环节中的中间件产品的热点 Key, 如 Nginx, 缓存, RPC 服务框架等.
2. 建立一个热点上报和可以按需订阅的热点服务的下发规范, 主要目的是通过交易链路上各个系统访问的时间差, 把上游已经发现的热点透传给下游系统, 提前做好保护. 比如大促高峰期, 详情系统是最早知道的.
3. 将上游系统收集的热点数据发送到热点服务台, 然后下游系统(比如交易系统)就会知道哪些商品会被频繁调用, 然后做热点保护.

#### 处理热点数据
常用的思路有: 优化, 限制, 隔离.
优化热点数据最有效的办法就是缓存热点数据.
限制更多的是一种保护机制. 防止因某些热点数据占用太多服务器资源, 而使其他请求始终得不到服务器的处理.
隔离也是为了防止 1% 的请求影响到另外的 99%, 隔离出来后也更方便对这 1% 的请求做针对性的优化.
具体到 "秒杀" 业务, 我们可以在以下几个层次实现隔离:
1. 业务隔离. 把秒杀系统做成一做可以提前预知的活动.
2. 系统隔离. 一般指运行时隔离. 可以通过分组部署或使用单独入口(单独域名)的方法防止影响到其他业务.
3. 数据隔离. 对热点数据使用单独的 Cache 和数据库.


### 流量削峰
秒杀请求在时间上高度集中于某一特定的时间点. 这会导致一个特别高的流量峰值, 它对资源的消耗是瞬时的.
对于秒杀这个场景来说, 最终能够抢到商品的人数是固定的. 并发度越高, 无效请求也越多. 但从业务上来说, 秒杀活动是希望更多的人来参与的.
服务器的处理资源能力是恒定的. 但是由于要保证服务质量, 我们对很多场景的资源需求只能按忙时来预估, 这就会导致资源的浪费. 削峰的存在, 一是可以让服务端处理更加平稳, 二是可以节省服务器的资源成本.

#### 排队
即用消息队列来缓冲瞬时流量. 把同步的直接调用转换成异步的间接推送. 中间通过一个队列在一端承接瞬时的流量洪峰, 在另一端平滑地将消息推送出去.

#### 答题
一是防止部分买家使用秒杀器作弊. 二是延缓请求.
这个功能就是把峰值的请求拉长, 从以前的 1s 内延长到 1s~10s.
秒杀答题的逻辑是:
1. 题库生成. 生成能够防止机器破解的题库.
2. 题库的推送. 用来保证每次用户请求的题目是唯一的, 防止作弊.
3. 题库图片生成. 由于答题时网络比较拥挤, 应该把题库图片提前推送到 CDN 上并进行预热.

可以将题目和答案不可逆加密后推送到客户端, 在用户提交前先在客户端进行验证, 以减少无效请求.

#### 分层过滤
对请求进行层层过滤, 从而去除一些无效的请求. 假如请求分别经过 CDN, 前台读系统, 后台系统和数据库这几层, 那么:
1. 大部分数据和流量在用户浏览器或者 CDN 上获取, 这一层可以拦截大部分数据的读取.
2. 经过前台读系统时数据尽量走 Cache, 过滤一些无效的请求.
3. 在后台系统中对数据做二次检验, 对系统做好保护和限流, 这样数据量和请求就进一步减少.
4. 最后在数据层完成数据的强一致性校验.

这样就像漏斗一样, 尽量把数据量和请求量一层一层地过滤和减少了.
分层过滤的核心思想是: 在不同的层次尽可能地过滤掉无效请求, 让 "漏斗" 最末端的才是有效请求. 
尽量将不影响性能的校验放在前面.

### 服务器优化技巧
你想要提升性能, 首先肯定要知道哪些因素对于系统性能的影响最大.
系统服务端性能一般用 QPS(Query Per Second, 每秒请求数)来衡量. 还有一个和 QPS 相关的响应时间(RT, Respone Time), 可以理解为服务器处理响应的耗时.
理论上 `QPS = (1000ms/RT) * 线程数量`.
对于大部分 Web 系统而言, RT 一般都是由 CPU 执行时间和线程等待时间(比如 RPC, IO 等待, Sleep, Wait 等)组成. 即服务器在处理一个请求时, 一部分是 CPU 本身在做运算, 还有一部分是在各种等待.
可以通过增加代理服务器的处理线程数, 来弥补响应时间对代理服务器的 QPS 的影响. 但线程并不是越多越好, 因为线程本身也是消耗资源的, 线程越多线程间切换成本越高. **很多多线程的场景都有一个默认配置, 即 `线程数 = 2 * CPU 核数 + 1`. 还有一个根据最佳实践得出的公式: `线程数 = [(线程等待时间 + 线程 CPU 时间)/线程 CPU 时间] * CPU 数量`. 当然, 最好的办法是通过性能测试来发现最佳的线程数**.
真正对性能有影响的是 CPU 的执行时间. 有很多 CPU 诊断工具可以发现 CPU 的消耗, 如 JProfiler 和 Yourkit. 它们可以列出整个请求中每个函数的 CPU 执行时间. 
当 QPS 达到极限时, 如果服务器的 CPU 使用率不超过 95%, 那么表示 CPU 还有提升空间, 要么是有锁限制, 要么是有过多的本地 I/O 等待发生.

#### 如何优化系统
1. 减少编码.

    Java 的编码运行比较慢. 在很多场景下, 只要涉及字符串的操作(如输入输出操作, I/O 操作)都比较耗 CPU 资源, 不管是磁盘 I/O 还是网络 I/O, 因为都需要将字符转换成字节, 而这个转换必须编码.
    如何减少编码呢? 例如网页输出可以直接进行流输出. 即用 `resp.getOutputStream()` 函数写数据, 把一些静态的数据提前转化为字节.
    
1. 减少序列化.

    序列化往往是在 RPC 中发生的, 因此避免或者减少 RPC 就可以减少序列化.
    一种方案是将多个关联性比较强的应用进行 "合并部署". 所谓 "合并部署", 就是把两个原本在不同机器上的不同应用合并部署到一台机器同一个 Tomcat 容器中, 且不能走本机的 Socket, 这样才能避免序列化的产生.
    
1. Java 极致优化.

    直接使用 Servlet 处理请求. 绕过传统 MVC 框架的一大堆复杂处理逻辑.
    直接输出流数据. 使用 `resp.getOutputStream()` 而不是 `resp.getWriter()` 函数, 可以省掉一些不变字符数据的编码, 从而提升性能; 数据输出时使用 JSON 而不是模板引擎.
    
1. 并发读优化.

    采用应用层的 LocalCache, 即在秒杀系统的单机上缓存商品相关的数据.
    静态数据提前缓存, 提前预热.
    像库存这类动态数据, 采用 "被动失效" 的方式缓存一定时间(一般是数秒), 失效后再去拉取最新的数据.
    **读的场景允许一定的脏数据, 等到真正写数据时再保证最终的一致性(如数据库), 通过在数据的高可用性和一致性之间的平衡, 来解决高并发的数据读取问题**.
    
#### 其它
减少数据, 数据分级(动静分离), 减少中间环节, 增加预处理等.

首先是 "发现短板", 比如光速(即数据传输是有物理距离相关的), 网速(千兆下 10K 数据的极限 QPS 为 1.25 万. QPS = 1000Mbps/8/10KB), 网络结构(交换机/网卡的限制), TCP/IP, 虚拟机(内存/CPU/IO 等资源限制)和应用本身的一些瓶颈等.
再次, 就是数据分级, 也就是要保证首屏为先, 重要信息为先, 次要信息则异步加载.
最后, 就是要减少中间环节, 减少字符到字节的转换, 增加预处理去掉不需要的操作.

### "减库存" 设计的核心逻辑
在正常的电商平台购物场景中, 用户的实际购买过程一般分为两步: 下单和付款. 减库存一般有如下几种方式:
* 下单减库存. 但要注意, 有些人下完单可能并不会付款.
* 付款减库存. 有可能会出现买家下单后付不了款的情况, 因为可能商品已经被其他人买走了.
* 预扣库存. 买家下单后, 库存为其保留一定时间, 超过这个时间, 库存将自动回调供其他买家继续购买.

#### 秒杀系统的减库存
秒杀的商品很少会出现下单后不付款的情况, 再加上卖家对秒杀商品的库存有严格限制, 所以秒杀商品采用 "下单减库存" 更加合理.
"下单减库存" 可通过将数据库字段设置为无符号整数来防止字段值为负.
把库存数据放在 Cache 中, 可大大提升读性能.
如果减库存的逻辑非常单一, 可以将其放在缓存系统中实现. 如果逻辑复杂需要事务, 还是得在数据库中完成减库存操作.
要解决并发锁问题, 有两种方法:
* 应用层做排队. 防止热点商品占用太多数据库连接.
* 数据库层做排队. 应用层只能做到单机的排队, 这种排队方式控制并发的能力仍然有限, 所以如果能在数据库层做全局排队是最理想的.

### Plan B
当一个系统面临持续的大流量时, 它其实很难单靠自身调整来恢复状态, 你必须等待流量自然下降或者人为地把流量切走才行.
没有人能够提前预估所有情况, 意外无法避免. 我们可以在系统达到不可用状态之前就做好流量限制, 防止最坏情况发生. 即任何一个系统, 都需要 "反脆弱".

#### 高可用建设

![高可用系统建设](https://files-kyo.oss-cn-hongkong.aliyuncs.com/Fv9UaaWiMw38bY7ilRWnXNBjB5x0.png)

1. 架构阶段: 主要考虑系统的可扩展性和容错性. 要避免出现单点问题.
2. 编码阶段: 编码最重要的是保证代码的健壮性. 例如涉及远程调用问题时, 要设置合理的超时退出机制, 防止被其他系统拖垮, 也要对调用的返回结果集有预期, 防止返回的结果超出程序处理范围, 最常见的做法就是对错误异常进行捕获, 对无法预料的错误要有默认处理结果.
3. 测试阶段: 主要是保证测试用例的覆盖度, 保证最坏情况发生时, 也有相应的处理流程.
4. 发布阶段: 发布时最容易出现错误, 因此要有紧急的回滚机制.
5. 运行阶段: 对系统的监控要准确及时, 发现问题能够准确报警并且报警数据要准确详细, 以便于排查问题.
6. 故障发生: 故障发生时首先最重要的就是及时止损, 防止造成重大资产损失. 然后就是要能够及时恢复服务, 并定位原因解决问题.

网站的高可用建设是基础. 要在预防(建立常态的压力体系, 例如上线前的单机压测到上线后的全链路压测), 管控(做好线上运行时的降级, 限流和兜底保护), 监控(建立性能基线来记录性能的变化趋势以及线上机器的负载报警体系, 发现问题及时预警)和恢复体系(遇到故障要及时止损, 并提供快速的数据订正工具等)这些地方加强建设.
要保证高可用建设的落实, 你不仅要做系统建设, 还要在组织上做好保障. 高可用其实就是在说 "稳定性". 稳定性是一个平时不重要, 但真出了问题就会要命的事儿. 所以很可能平时业务发展良好, 稳定性建设就会给业务让路, 相关的稳定性负责人员平时根本得不到重视, 一旦遇到故障却又成了 "背锅侠".

#### 降级
所谓 "降级", 就是当系统的容量达到一定程度时, 限制或者关闭系统的某些非核心功能, 从而把有限的资源保留给更核心的业务.
它是一个有目的, 有计划的执行过程, 所以对降级我们一般需要有一套预案来配合执行. 如果我们把它系统化, 就可以通过预案系统和开关系统来实现降级.
执行降级无疑是在系统性能和用户体验之间选择了前者, 会影响部分用户的体验.

#### 限流
限流就是当系统容量达到瓶颈时, 我们需要通过限制一部分流量来保护系统.
总体来说, 限流既可以是在客户端限流, 也可以是在服务端限流. 此外, 限流的实现方式既要支持 URL 以及方法级别的限流, 也要支持基于 QPS 和线程的限流.
在限流的实现手段上来讲, 最大 QPS 很容易通过压测提前获取. 线程数限流可以通过连接池实现.

#### 拒绝服务
当系统负载达到一定阈值时, 例如 CPU 使用率达到 90% 或者系统 load 值达到 2*CPU 核数时, 系统直接拒绝所有请求, 这种方式是最暴力但也最有效的系统保护方式.


















