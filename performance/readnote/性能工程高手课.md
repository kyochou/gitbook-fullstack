# 性能工程高手课  
## 认识代码性能和系统容量效率  
性能好的代码, 可以用四个字来概括: "多快好省". "多" 是指吞吐量大; "快" 就是服务延迟低; "好" 就是扩展性好; "省" 即资源使用量低(也即资源利用率高).  
对低层的软硬件构成越是了解, 就越有可能设计出性能优越的模块和应用程序(在设计系统时充分考虑硬件的性能特征和技术趋势).  
从公司运营的角度来看, 整个互联网大服务的性能才是我们每个程序员应该真正关心和负责的. 我们每个人都需要从这个大局出发来考虑和分析问题, 来设计自己的模块以及各种交互机制.  
虽然性能优化的方法和最终解决方案或许看起来很简单直白, 但是要知道在哪里做优化和做什么样的优化, 却需要很多的测试和分析的工作经验.  
性能工程师会首先观察各种参数, 甚至进行主动的场景测试. 根据结果做出分析, 最终确定性能问题的根因.  
复杂问题都需要比较广的知识. 然后大胆假设, 再通过实践验证.  
我们在讲任何某一部分的性能时, 都要假设其他模块和资源不是瓶颈.  
  
## 性能定律和数理基础  
### 性能工程三定律  
系统容量往往指的是一个系统的性能瓶颈能力, 可以是 QPS(Query Per Second, 也就是请求数), 网络处理能力, 存储能力等等.  
  
#### 帕累托法则  
也被称为 80/20 法则, 关键少数法则, 二八法则.  
人们在生活中发现很多变量的分布是不均匀的. 在很多场景下, 大约 20% 的因素操控着 80% 的局面. 也就是说, 所有的变量中, 比较重要的只有 20%, 是所谓的 "关键少数", 剩下的多数, 却没有那么重要.  
这个法则的精髓是, 我们的生活和自然界万物的分布不是均匀的, 总有些因素比其他因素更重要.  
  
![程序中的二八法则](https://static001.geekbang.org/resource/image/9d/1d/9d99b547cbf2074144203f2ec2806c1d.png)  
  
#### 阿姆达尔定律  
阿姆达尔定律其实是通用扩展定律(USL, Universal Scalability Law)的简化版本. 用于衡量处理器进行并行处理时总体性能的提升度.  
根据阿姆达尔定律描述, 科学计算中用多处理器进行并行加速时, 总体程序受限于程序所需的串行时间百分比. 譬如说, 一个程序 50% 是串行的, 其他一半可以并行, 那么, 最大的加速比就是 2. 无论用多少处理器并行, 这个加速比不可能提高到大于 2. 所以在这种情况下, 改进程序本身的串行算法可能比用多核处理器并行更有效.  
阿姆达尔定律对我们进行性能优化的指导意义有:  
1. 优先加速占用时间最多的模块, 因为这样可以最大限度地提升加速比.  
2. 对一个性能优化的计划可以做出准确的效果预估和整个系统的性能预测.  
  
#### 利特尔法则  
这个法则描述的是: 在一个稳定的系统中, 长期的平均客户人数(N)等于客户抵达速度(X)乘以客户在这个系统中平均处理时间(W), 也就是说 N=X*W.  
  
![利特尔法则](https://static001.geekbang.org/resource/image/40/89/408c046dc1722db99058ce0bbcf94389.png)  
  
利特尔法则在性能优化中的用处有:  
1. 帮助我们设计性能测试的环境. 比如当我们需要模拟一个固定容量的系统时, 那么性能测试的客户请求流量速度和每个请求的延时都需要仔细考虑.  
2. 帮助我们验证测试结果的正确性.   
  
### 概率统计和排队论  
#### 概率和置信区间  
概率(Probability), 是一个在 0 到 1 之间的实数, 是对随机事件发生之可能性的度量.  
贝叶斯定理(Bayes' theorem)描述的是在已知一些条件下, 某事件的发生概率. 贝叶斯定理的一个用途在于通过已知的任意三个概率函数推出第四个.  
置信区间(Confidence interval)是对产生样本的总体参数分布中的某一个未知参数值, 以区间形式给出的估计.  
置信区间是对分布(尤其是正态分布)的一种深入研究. 通过对样本的计算, 得到对某个总体参数的区间估计, 展现为总体参数的真实值有多少概率落在所计算的区间里.  
平均值(Mean), 它的目的是确定一组数据的均衡点. 不足之处是它容易受极端值影响.  
中位数(Median), 将数值集合划分为相等的上下两部分, 排序后处于最中间的数.   
四分位数(Quartile), 把所有数值由小到大排列, 并分成四等份, 处于三个分割点位置的数值就是四分位数.  
百分位数(Percentile), 可以看作是四分位数的扩展, 是将一组数据从小到大排序, 某一百分位所对应数据的值就称这一百分位的百分位数. 百分位数不容易受极端值影响, 因为有 100 个位置可以选取.  
方差/标准差(Variance, Standard Variance), 描述的是变量的离散程度, 也就是该变量离其期望值的距离.  
  
#### 重要的分布模型  
泊松分布(Poisson distribution)适合于描述单位时间内随机事件发生次数的概率分布.  
二项分布(Binomial distribution)是 n 个独立的 是/非 试验中成功次数的离散概率分布.  
正态分布(Normal distribution)也叫高斯分布, 其分布曲线呈钟型, 两头低, 中间高, 左右对称, 因此经常被称之为钟形曲线. **正态分布的重要性在于, 大多数我们碰到的未知数据都呈正态分布状. 这意味着我们在不清楚总体分布情况时, 可以先用正态分布来模拟**.  
  
#### 排队的理论  
排队论(Queuing Theory), 也被称为随机服务系统理论.  
排队的模型有很多, 常用的有单队列单服务台和多队列多服务台.  
  
### 性能数据分析  
#### 算法的时间复杂度(Time Complexity)  
复杂度一般表示为一个函数, 来定性描述该算法的期待运行时间, 常用大 O 符号表述.  
常见的复杂度按从快到慢依次是:  
1. 常数时间, $O(1)$;  
2. 对数时间, $O(Log(N))$;  
3. 线性时间, $O(N)$;  
4. 线性对数时间, $O(N*Log(N))$;  
5. 二次时间, $O(N^2)$;  
6. 指数时间, $O(2^N)$;  
  
![算法的时间复杂度](https://static001.geekbang.org/resource/image/1e/00/1e07480a265a7f017463bffba2293b00.png)  
  
大体上, 前四种算法复杂度比较合理, 后面两种在数据量大的时候, 运行时间很快就会超标.  
  
#### 性能数据分析的目的  
最常见的性能数据就是客户的访问延迟, 吞吐量和运行时间.  
当收集到性能数据以后, 我们首先要判断它们的值到底是正常还是不正常.  
如果观测到针对某个指标的一系列性能数据, 那就需要判断这个指标有没有随着时间或者其他变量的变化而变差或变好.  
我们还经常需要对某个性能指标做预测. 这种情况就需要研究数据的趋势(Trend). 根据情况做些预测分析, 比如根据这个指标的历史数据来进行曲线拟合.  
  
#### 对一个时间序列的分析  
一般来讲, 一个性能指标, 按照时间顺序得到的观测值, 可以看作是一个时间序列.  
针对一个性能数据的时间序列, 如何看数据的规律和趋势呢? 经常使用的方法是进行线性回归分析(Linear Regression). 线性回归是通过拟合自变量与因变量之间最佳线性关系, 来预测目标变量的方法. 线性回归往往可以预测未来的数据点. 比如根据过去几年的每月消费支出数据来预测明年的每月支出是多少.  
  
#### 对不同时间序列的分析  
在一大堆性能数据面前, 经常需要比较各个性能指标的时间序列来确定一个系统和服务的瓶颈, 也就是最制约系统性能扩展的资源.  
在多数情况下, 瓶颈资源是常见的几种, 如 CPU, 网络, 内存和存储.  
数据的相关性是指数据之间存在某种关系, 可以是正相关, 也可以是负相关.  
在很多情况下, 比单纯数字大小更重要的是数据的趋势, 比如某个时期是上升还是下降, 变化的幅度有多大等等.  
  
  
### 性能数据展示  
数据的展示根据场景有不同的目的. 每一种场景下, 数据展示要根据你的具体目的, 听众的特点和内容的特点而采用合适的图表. 然后用这些图表做支持, 把一个精美的数据分析的 "故事" 讲出来.  
性能数据展示的目的主要有:  
* 向上级报告性能趋势和流量预测的结果;  
* 向运维部门描述性能问题的根因分析;  
* 向开发部门建议性能提升和代码优化;  
  
#### 数据图表的种类  
* 表格(Table): 优点是可以用结构化的方式显示大量信息. 但很多用户其实对数据的趋势比具体的数值更有兴趣;  
* 线图(Line): 用于展示变量在一段时间内的变化或趋势. 也可以直观地显示出多个变量之间的关系.  
* 面积图(Area): 面积图的重点是阴影线下方的区域. 多组数据可选择用叠加面积图的形式显示.  
* 柱状图和条形图(Bar): 用于比较不同类别的数量.  
* 散点图(Scatter): 显示沿两个轴绘制的两个变量的值, 用点的模式揭示它们之间存在的任何相关性.  
* 气泡图(Bubble): 类似于散点图, 但可以用气泡的大小表示第三个变量.  
* 饼图(Pie): 当需要显示比例数据或者百分比时, 饼图最佳. 饼图最好用来显示六个或更少的类别.  
* 圆环图(Donut): 类似于饼图.  
* 树形图(Treemaps): 树形图对于显示类别和子类别之间的层次结构和比较值非常有用, 同时也能保留较多细节. 树形图可以帮助我们很直觉地感知哪些区域最重要.  
* 热图(Heatmaps): 热图以表格格式来表示数据, 但每个格子会给予不同含义的颜色.  
  
### 常用性能数字  
  
```bash  
1s == 1000ms(毫秒)  
1ms == 1000us(微秒)  
1us == 1000ns(纳秒)  
```  
  
#### 存储  
对所有的存储来说, 有三个基本的性能指标:  
* IO 读写延迟. 一般是用 4KB 大小的 IO 做基准来测试;  
* IO 带宽. 一般是针对比较大的 IO 而言;  
* IOPS. 就是每秒可以读写多少个小的随机 IO.  
  
![存储介质和它们的性能数值](https://static001.geekbang.org/resource/image/46/65/4601c4eb6ecc8e48643d189e7af72565.jpg)  
  
#### CPU 和内存  
比较不同 CPU 硬件的性能时, MIPS 是一个很好的指标. 一般来讲, MIPS 越高, CPU 性能越高.  
MIPS 指每秒执行的百万指令数. 可以通过主频和 IPC(instructions per cycle, 周期指令数) 相乘得到.  
  
#### 网络相关  
网络的传输延迟是和地理距离相关的. 网络信号传递的速度不可能超过光速. 一般光纤的传递速度是每毫秒 200 公里左右. 如果考虑往返时间(RTT, Round Trip Time), 那么可以大致认为每 100 公里就需要 1ms.  
  
![RTT 与距离](https://static001.geekbang.org/resource/image/d0/cd/d0c2d6ebd3efa2dd8666cb26fb8002cd.jpg)  
  
  
  
## 性能测试  
### 性能测试的种类  
性能测试的目的是确保软件应用程序在一定的负载流量下运行良好.  
性能测试的目的大体上有:  
* 测量服务速度(Speed): 包括延迟和吞吐率两个指标;  
* 测量可扩展性(Scalability);  
* 测量稳定性(Stability);  
* 测量性能瓶颈(Performance Bottleneck): 性能瓶颈是应用程序和系统中的最影响整体性能的因素;  
  
性能测试的种类有:  
* 冒烟测试(Smoke Testing): 是开发人员在开发环境里执行的简单测试, 以确定新的程序代码不出故障;  
* 耐力测试(Endurance Testing), 浸泡测试(Soak Testing): 是长时间测试具有预期负载量的系统, 以验证系统的行为是否正常;  
* 基准测试(Benchmark Testing), 性能回归测试(Performance Regression Testing): 是着重 "前后" 比对的测试. 代码的演化过程中经常需要确保新的代码不会对整个模块或系统的性能产生任何不好的影响. 执行基准测试的重点是保证前后测试环境的一致;  
* 负载测试(Load Testing): 用于验证被测试系统或者程序是否可以处理预期的负载流量, 并验证正常和峰值负载条件下的系统和程序行为;  
* 断点测试(Breakpoint Testing): 这种测试的过程是随着时间的推移而增大流量负载, 同时监视系统的预定故障条件. 断点测试可以用来确定系统将达到其所需规范或服务水平协议的最大容量, 并且自动采取措施来纠正或者缓解. 比如云计算环境中, 我们可以设置某种性能断点, 用它们来驱动某种扩展和伸缩策略;  
* 尖峰测试(Spike Testing): 用于确定系统在负载(比如用户请求数)突然变化时的系统行为;  
* 可扩展性测试(Scalability Testing): 或者叫可伸缩性测试. 用于确定一个程序和系统的非功能性特征能不能在变化的环境里合理扩展;  
* 容量测试(Capacity Testing): 或者叫体积测试(Volume Testing). 用于确定一个单位容量能够支持的最大负载. 只有进行彻底的容量测试, 并有相对应问题的解决方案, 才可以使我们能够避免将来出现潜在的超载问题;  
* 瓶颈测试(Bottleneck Testing): 它的目的是找到被测试程序的最制约的资源类型;  
* 压力测试(Stress Testing): 在负载增加到超过系统设计预期后观察和验证系统的行为. 压力测试的目的是为了暴露系统的问题;  
  
  
### 性能测试的规划和步骤  
  
![性能测试的过程](https://static001.geekbang.org/resource/image/72/38/72857508b6a54ce2da0467ce9249c138.png)  
  
#### 决定测试对象  
测试的对象一般叫 SUT(System Under Test), 它可以是一段代码, 一个模块, 一个子系统或者一个整体系统.  
**搞清楚 SUT 的重要之处, 是让测试做到有的放矢. 除了 SUT 本身, 其他所有的模块和构件在整个性能测试的过程中都不能有任何性能瓶颈**.  
  
#### 决定测试的性能指标  
常用的性能指标有:  
* 响应时间: 用户关注的指标;  
* 吞吐量: 业务关注的指标;  
* 资源利用率: 系统关注的指标;  
  
#### 决定测试指标的度量  
#### 决定性能测试的期望结果  
#### 性能测试的规划  
包括 负载流量的特征, 负载如何注入, 测试的数据, 黑盒还是白盒, 测试的工具, 测试的环境 等.  
  
#### 性能测试的执行  
测试结果的可重复性非常重要. 性能测试和性能优化很多情况下是一个长期的行为, 所以需要固定测试性能指标, 测试负载, 测试环境, 这样才能客观反映性能的实际情况, 也能展现出优化的效果.  
  
#### 分析测试结果  
几乎所有的性能测试, 都需要反复进行多次, 才能达到满意的效果.  
  
  
### 性能测试工具  
一个稍微健全的测试工具会包括:  
* 负载生成模块: 负责产生足够的流量负载;  
* 测试数据收集模块: 负责获取测试的数据, 包括具体的各种性能数据;  
* 结果分析和展示模块;  
* 资源监控模块;  
* 控制中心模块;  
  
![测试工具组成](https://static001.geekbang.org/resource/image/1c/4f/1c4e724cff73f9595bb63b49a5cd3a4f.png)  
  
#### Web 测试场景  
常用工具有 JMeter, LoadRunner, Locust 等.  
  
#### 系统测试场景  
UnixBench 是 Unix 系统下的性能测试工具.  
Perf 是 Linux 下最普遍使用的性能分析工具. 它既可以分析指定应用程序的性能问题, 也可以用来分析内核的性能问题.  
  
#### 数据库测试场景  
SysBench 主要用于测试数据库性能, 但也可以测试 CPU, 内存, 文件系统等性能.  
mysqlslap 是 MySQL 自带的压力测试工具.  
  
#### 文件 IO 和存储测试场景  
ioZone 可以测试不同操作系统中的文件系统的读写性能.  
dd 是 Linux 中测试硬盘读写性能的工具.  
  
#### 网络测试场景  
Netperf 主要针对基于 TCP 或 UDP 的传输进行测试.  
Iperf 可以测试最大 TCP 和 UDP 带宽性能.  
  
#### 移动 App 测试场景  
  
  
### 经验和教训  
性能测试的一个关键是保证测试结果可靠, 可重复, 否则就没有意义.  
  
![性能测试要点](https://static001.geekbang.org/resource/image/ee/a5/eee41a2f022ed7c88ea2a31c5b4157a5.png)  
  
#### 测试规划  
1. 详细记录测试环境和测试过程. 测试环境不同, 性能测试的结果可能会迥异. 包括操作系统和程序的版本号, 各种软件参数的设置等. 记录测试环境的目的是为了以后的各种分析. 比如发现两次测试结果不匹配, 需要找到不匹配的原因, 那么这些测试环境就是相当关键的信息;  
2. 快速复位测试环境. 一般来讲, 会把所有的配置和参数都恢复一下. 包括重新拷贝文件, 重置配置参数, 清空各种缓存等;  
3. 足够的负载请求和数据. 除了合理清空缓存外, 更有效地方式是保证测试时间足够长, 测试的负载请求足够多和数据足够多样化, 从而最大限度地减少或者掩盖缓存等其他因素的影响;  
  
#### 测试进行  
1. 性能数据日志要适当输出;  
2. 测试环境要稳定. 一般是尽量在一个独立无干扰的环境中进行测试, 加上每次测试都准确地恢复测试环境, 就能最大限度地保证测试环境的稳定;  
  
#### 结果分析  
1. 根因分析要由易到难. 从最明显的性能瓶颈来开始, 往往可以事半功倍;  
2. 几种测试最好互相验证;  
3. 测试结果和生产环境比较;  
  
  
### 工程集成  
智能来自于对大数据的分析和机器学习.  
  
## 性能分析  
### 概述  
在整个性能优化的世界里, 性能测试是基础.  
#### 外部指标  
* 服务延迟(Service Latency): 指客户发出的请求被成功服务的时间. 即一次 RTT 的时长;  
* 吞吐率(Throughput): 指单位时间(如每秒)可以成功处理的请求数或任务数. 这一指标和服务延迟相辅相成, 一个注重时间, 一个注重空间. 一个系统的外部性能主要受这两个条件的约束, 缺一不可;  
* 资源使用率(Resource Utilization): 这一指标主要是面向系统容量;  
  
我们在规定延迟标准时, 除了均值, 还需要定义百分位数的可接受值.  
性能问题归根结底是某个资源受到限制, 不够用了.   
总体上来讲, 性能分析的目的, 是提供高性能, 低延迟, 高效率的服务.  
性能分析和优化的首要原则: 当我们怀疑性能有问题时, 应该通过合理的测试, 日志分析, 并作合适的剖析(Profilling), 来分析出哪里有问题, 从而有的放矢, 而不是凭感觉, 撞运气.  
  
### CPU 篇  
CPU 的 Turbo 模式, 就是让 CPU 的主频提高. 目的是可以让处理器在特殊情况下, 用提高功耗的代价来增加主频, 从而获得更高的性能.  
通常, 一个传统的处理器在线程之间切换, 可能需要几万个时钟周期, 而一个具有 HT(Hyperthreading) 超线程技术的处理器只需要 1 个时钟周期. 因此大大减小了线程之间切换的成本, 从而最大限度地让处理器满负荷运转.  
计算机的 CPU 数量 = 处理器数 * 核数 * 超线程数  
衡量一个应用程序对 CPU 的使用效率时, 往往会考察 CPI(Cycles Per Instruction) 和 IPC(Instructions Per Cycle).  
  
### 内存篇  
CPU 缓存通常分成三个级别: L1, L2, L3. 一般而言, 每个核上都有 L1 和 L2 缓存. 所有核共享 L3 缓存.  
L1 缓存分成两部分: 一个用于存数据, 一个用于存指令.  
为什么要采用多级缓存, 并逐级增加缓存大小呢? 这个目的, 就是为了提高各级缓存的命中率, 从而最大限度地降低直接访问内存的概率.  
  
![CPU 访问缓存的时钟周期](https://static001.geekbang.org/resource/image/75/53/754b694aed8f28c2e215876fc596cf53.png)  
  
**计算机性能方面的一个趋势是, 内存越来越变成主要的性能瓶颈**. 内存对性能的制约包括三个方面: 内存大小, 内存访问延迟和内存带宽.  
采用高效的, 使用内存少的算法和数据结构以减小内存的使用, 从而可以更多的使用缓存.  
尽量降低数据和程序的大小, 从而提高缓存的命中率. 因为缓存可以覆盖的代码和数据比例会增大.  
**程序使用的内存大小很关键, 是影响一个程序性能的重要因素. 我们应该让程序尽量少的使用内存, 从而提高 CPU 缓存的命中率**.  
一个系统的空闲内存越多, 应用程序向操作系统申请内存的时候, 就能越快地拿到所申请的内存.  
我们写程序时, 或许习惯直接使用 new, malloc 等 API 申请分配内存, 这样做有个很大的缺点, 就是所申请内存块的大小不定. 当这样的内存申请频繁操作时, 会造成大量的内存碎片, 导致系统性能下降. 一般来讲, 开发应用程序时, 采用内存池可以看作是一种内存分配方式的优化.  
我们部署应用程序时, 最好将访问相同数据的多个线程放在相同的处理器上. 根据情况, 有时候也需要强制去绑定线程到某个节点或者 CPU 核上.  
  
### 存储篇  
存储系统最重要的三大性能指标: IOPS, 访问延迟和吞吐率(带宽).  
  
### 网络篇  
网络性能的五个常用指标是:  
* 可用性: 使用 `ping` 命令可以判断远端的机器是否连通;  
* 响应时间;  
* 网络带宽容量;  
* 网络吞吐量;  
* 网络利用率;  
  
## 性能优化  
### 六大原则  
1. 优先查最大的性能瓶颈.  
2. 确诊性能问题的根因.  
3. 要考虑各种情况下的性能. 针对某个具体场景提出的解决方案, 多半并不能适应所有的场景. 我们经常需要在不同性能指标间权衡, 以找到一个最优解能达到总体和整体最优.  
4. 不要过度地反常态优化. 性能优化的目标, 是追求最合适的性价比或最高的投入产出比.  
5. 不要过早的不成熟优化. 过早优化乃万恶之源.  
6. 不要表面的肤浅优化. 如果对一个程序或服务没有全局的把握, 没有理解底层运行机制, 任何优化方案都很难达到最好的优化效果.  
  
### 十大策略  
1. 用时间换空间. 可通过修改数据结构, 压缩数据等方式实现.  
2. 用空间换时间.  
3. 预先/提前处理. 如 `preload` 和 `prefetch`, 预读/预取功能.  
4. 延后/惰性处理. 如 COW(Copy On Write, 写时复制).  
5. 并行操作.  
6. 异步操作.   
7. 缓存数据. 缓存的本质是加速访问.   
8. 批量合并处理. 在有 IO(如网络 IO 或磁盘 IO) 时, 合并操作和批量处理往往能提升吞吐量, 提高性能.  
9. 先进的算法.  
10. 高效的数据结构.  
  
### CPU 案例  
CPU 的最后一级缓存(LLC)如果命中率不高的话, 对系统性能会有极坏的影响.  
使用 Perf 工具可统计 CPU 的 LLC 的命中情况:  
```shell  
perf stat -e LLC-loads,LLC-load-misses,LLC-stores,LLC-store-misses  
```  
  
如何降低 LLC 的不命中率:  
1. 缩小数据结构, 让数据变得紧凑.  
2. 用软件方式来预取数据.   
3. 去除伪共享缓存. 内存缓存系统中, 一般是以缓存行(Cache Line)为单位存储的, 最常见的缓存行大小是 64 个字节. **我们开发程序时, 不同线程的数据要尽量放到不同的缓存行(内存对齐), 避免多线程同时频繁地修改同一个缓存行**.  
  
### 系统案例  
指令地址映射的不命中率(iTLB miss rate)太高, 会导致程序运行的不够快.  
当 iTLB 未命中率很高时, CPU 将花费大量周期来处理未命中指令, 这就导致指令执行的速度变慢.  
通过优化软件的二进制文件可以减小 iTLB 的不命中率.  
FDO(Feedback-Directed Optimization, 基于反馈的优化)就是把一个程序放在生产环境中运行, 剖析真实的生产数据, 并且用这些信息来对这个程序进行精准的优化. 比如, 可以确切地知道在生产环境中, 每个函数的调用频率.  
采用大的页面(hugepagesz), 也可以减小 iTLB 的不命中率.  
  
![提高 iTLB 的命中率](https://static001.geekbang.org/resource/image/e8/79/e8286137049016140a5433d5cdbf0979.png)  
  
### 存储案例  
SSD 的空闲可用空间越多, 内部垃圾收集的开销就越低, 就越有可能降低写入放大系数.    
Trim 的使用, 虽然带来了降低 SSD 损耗的好处, 但也带来了一些坏处, 特别是 IO 访问可能延迟加大的问题.  
  
### 跨层案例  
研究表明, 200ms 的延迟, 是多数在线用户可以忍受的最大延迟.  
  
## 性能工程实践  
### 在生产环境进行真实的容量测试  
一般来说, 我们需要把生产环境的流量进行重定向, 让这些重定向的流量, 实时地驱动运行 SUT 的单个或者几个服务器.  
  
### 规划和控制数据库复制延迟的大小  
一切有关钱的事, 都是大事.  
  
### 让程序互不干扰  
当几个共存的应用程序共享有限的计算资源(包括内存和 CPU)时, 它们之间会相互影响.   
Linux 内存管理有一个页面回收的机制. 执行页面回收时, 操作系统需要进行页面扫描, 以检查已经分配页面的活动性. Linux 有两种策略来进行页面扫描: 后台扫描(由 kswapd 守护程序执行)和前台扫描(由进程自己执行). 通常情况下, 后台扫描就够了, 应用程序的性能一般不会受到影响. 但是当操作系统的内存使用非常大, 空闲页面严重不足时, Linux 就会启动前台页面回收, 也被称为直接回收或同步回收. 在前台页面回收过程中, 应用程序会停止运行, 因此对应用程序影响很大.  
当系统可用内存远远大于应用程序可能的内存占用量大小时, 就启动 THP, 因为系统不太可能在启动特定应用程序后出现内存压力. 否则就关闭 THP.  
  
### 优化网络传输速度  
数据传输慢可能有三个原因:  
1. 客户端应用程序的原因;  
2. 网络的原因;  
3. 服务器应用程序的原因;  
  
**通过使用 `netstat` 或 `ss` 命令查看客户端和服务器的 `RecvQ` 和 `SendQ` 即可查出问题所在**:  
1. 如果客户端上的接收队列 `RecvQ` 不为零, 则客户端应用程序是性能瓶颈;  
2. 如果服务器上的发送队列 `SendQ` 为零, 则服务器应用程序是性能瓶颈;  
3. 如果客户端的接收队列 `RecvQ` 为零, 而服务器的发送队列 `SendQ` 为非零, 则网络本身是性能瓶颈;  
  
![网络传输瓶颈](https://static001.geekbang.org/resource/image/31/f3/312fe519d3db2f20f9b44c547f0e00f3.png)  
  
### 彻底发挥 SSD 的潜力  
现在比较流行的有两种对 SSD 友好的文件系统. 第一种是适用于 SSD 的通用文件系统, 主要支持 Trim 的新功能, 如 Ext4 和 Btrfs. 第二种是专为 SSD 设计的文件系统, 如 NVFS, FFS/JFFS2 和 F2FS.  
除了文件系统, 数据库系统也可以设计成对 SSD 友好.  
第三个是数据基础架构层. 对于分布式数据系统的设计而言, 数据来源大体上有两个地方: 计算机上的本地磁盘或另一台计算机上的内存. 随着 SSD 的出现, 本地 SSD 变得比远程内存访问更为高效.  
在应用程序层, 有以下七大 SSD 友好的设计原则:  
  
![SSD 友好的设计原则](https://static001.geekbang.org/resource/image/a0/2d/a087788f0d74a2863366ca456f8c362d.png)  
  
  
## 容量规划与服务效率  
### 服务器的管理和部署  
从 CPU 的趋势来看, 摩尔定律正在失效. 每一代处理器将拥有更多的内核, 但运行频率一般要低于当前一代的处理器. 对软件来说, 应该着重于服务的水平扩展性, 就是通过多线程和多服务器来扩展服务的总体容量.  
DRAM 内存的趋势仍然会相对稀缺. 如果你的程序使用内存较多, 并且 SSD 这样的快速存储还不能满足服务的要求, 除了尽量减少内存使用外, 可以考虑采用 NVM(非易失性内存).  
硬盘方面, 其存储容量继续增加, 但增速开始降低. 并且硬盘提供的 IO 性能也没有增加. 为了利用这些更大容量的驱动器, 我们最好把硬件和软件设计一体化.  
不管网络技术如何发展, 还是需要尽量地减少跨数据中心和跨机架的网络流量, 也就是尽量让网络在本地消化掉. 因为越往外走, 网络的带宽总是越小.  
有一个有趣的趋势是, 未来是单处理器的天下. 现如今我们正进入高度集成的多核 CPU 时代, 也就是一个处理器上面有很多的核心. 一个处理器就已经有足够强大的计算能力. 单处理器的 CPU 利用率也会更高.  

  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
